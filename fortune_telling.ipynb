{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTTCVNGEhms6",
        "outputId": "619ad9e8-3428-4404-bed0-715d8ee27da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-21 17:23:56--  https://codalab.lisn.upsaclay.fr/my/datasets/download/dc591346-f10f-4b61-8932-d7a170e80dbf\n",
            "Resolving codalab.lisn.upsaclay.fr (codalab.lisn.upsaclay.fr)... 129.175.8.8\n",
            "Connecting to codalab.lisn.upsaclay.fr (codalab.lisn.upsaclay.fr)|129.175.8.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://miniodis-rproxy.lisn.upsaclay.fr/py3-private/public_data/0d30c66a-9624-42dd-8337-fdc6b66d1fe8/competition/7863/1/data/public_data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=EASNOMJFX9QFW4QIY4SL%2F20221021%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221021T172357Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=fc6ee9dc5abbb5bd36d945a3d91ea79e51aed3d05a33a7f9fbd0f710cc3cd9e7 [following]\n",
            "--2022-10-21 17:23:57--  https://miniodis-rproxy.lisn.upsaclay.fr/py3-private/public_data/0d30c66a-9624-42dd-8337-fdc6b66d1fe8/competition/7863/1/data/public_data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=EASNOMJFX9QFW4QIY4SL%2F20221021%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221021T172357Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=fc6ee9dc5abbb5bd36d945a3d91ea79e51aed3d05a33a7f9fbd0f710cc3cd9e7\n",
            "Resolving miniodis-rproxy.lisn.upsaclay.fr (miniodis-rproxy.lisn.upsaclay.fr)... 129.175.8.8\n",
            "Connecting to miniodis-rproxy.lisn.upsaclay.fr (miniodis-rproxy.lisn.upsaclay.fr)|129.175.8.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1157216 (1.1M) [application/zip]\n",
            "Saving to: ‘public_data.zip’\n",
            "\n",
            "public_data.zip     100%[===================>]   1.10M  1.97MB/s    in 0.6s    \n",
            "\n",
            "2022-10-21 17:23:58 (1.97 MB/s) - ‘public_data.zip’ saved [1157216/1157216]\n",
            "\n",
            "Archive:  public_data.zip\n",
            "  inflating: test_data.csv           \n",
            "  inflating: train_data.csv          \n",
            "  inflating: train_solution.csv      \n"
          ]
        }
      ],
      "source": [
        "!wget https://codalab.lisn.upsaclay.fr/my/datasets/download/dc591346-f10f-4b61-8932-d7a170e80dbf -O public_data.zip\n",
        "!yes | unzip public_data.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccYU07_AhqAv",
        "outputId": "66faaa8d-6804-46f9-95d4-309b3b32b0ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/fasttext_big* ."
      ],
      "metadata": {
        "id": "ntIE7h0qhrBC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train_all = pd.read_csv(\"train_data.csv\")\n",
        "df_ans = pd.read_csv(\"train_solution.csv\")\n",
        "assert (df_ans[\"id\"] == df_train_all[\"id\"]).all()\n",
        "df_train_all[\"category\"] = df_ans[\"category\"]\n",
        "\n",
        "df_train, df_val = train_test_split(df_train_all, train_size=0.8)\n",
        "df_train.reset_index(drop=True, inplace=True)\n",
        "df_val.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_test = pd.read_csv(\"test_data.csv\")"
      ],
      "metadata": {
        "id": "PNH6nYkzhtey"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import sys\n",
        "import re\n",
        "import pathlib\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm, trange\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity='all'\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ALBCKHnbhyGu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.8.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UylDIsjiwqH",
        "outputId": "632ef7c5-6148-4f16-b9bc-5dddcaba827d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==3.8.1\n",
            "  Downloading gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "import numpy as np\n",
        "\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "    '''Callback to log information about training'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_begin(self, model):\n",
        "        print(\"Epoch #{} start\".format(self.epoch))\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        print(\"Epoch #{} end\".format(self.epoch))\n",
        "        self.epoch += 1\n",
        "\n",
        "kvmodel = FastText.load('fasttext_big.model')\n",
        "emb_size = kvmodel.vector_size\n"
      ],
      "metadata": {
        "id": "GHwTN8HJh03y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NLP:\n",
        "    def __call__(self, text):\n",
        "        text = re.sub(r'[\\s]+', ' ', text).strip()\n",
        "        words = []\n",
        "        cw = \"\"\n",
        "        for elem in text:\n",
        "            elem = elem.lower()\n",
        "            if elem.isalpha():\n",
        "                cw += elem\n",
        "            else:\n",
        "                if cw:\n",
        "                    words.append(cw)\n",
        "                cw = \"\"\n",
        "                try:\n",
        "                    if elem not in (' ', '\\n') and elem and ord(elem) > 255:\n",
        "                        words.append(elem)\n",
        "                except:\n",
        "                    pass\n",
        "        if cw:\n",
        "            words.append(cw)\n",
        "        new_words = []\n",
        "        for elem in words:\n",
        "            if elem in \",.'-()?!\":\n",
        "                continue\n",
        "            if len(elem) == 0:\n",
        "                continue\n",
        "            new_words.append(elem)\n",
        "        if len(new_words) == 0:\n",
        "            new_words.append(\"<empty>\")\n",
        "        \n",
        "        return new_words\n",
        "nlp = NLP()"
      ],
      "metadata": {
        "id": "vt7QEJ_CiMiX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "\n",
        "def get_snts_emb(snts):\n",
        "    tokens = nlp(snts)\n",
        "    res = np.zeros(emb_size)\n",
        "    for tok in tokens:\n",
        "        res += kvmodel[tok]\n",
        "    return res\n",
        "\n",
        "target_snt = get_snts_emb(\"My future\")\n",
        "distants = np.zeros(df_train_all.shape[0])\n",
        "for i, snt in enumerate(df_train_all[\"message\"]):\n",
        "    distants[i] = spatial.distance.cosine(target_snt, get_snts_emb(snt))"
      ],
      "metadata": {
        "id": "e1wROF1qh_lR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*df_train_all[\"message\"].values[distants.argsort()[:5]], sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO-Ksg6iiqOl",
        "outputId": "9342da29-cc8e-4883-da1f-63081dbef8be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clarification from my friend.\n",
            "my bad\n",
            "My face, when always.\n",
            "oh my\n",
            "Separately, I will note my favorite way of \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DpBHERKoj9e6"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}